{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5f8b20f-713f-4a88-bd3e-16a918fe1c80",
   "metadata": {},
   "source": [
    "Gathering data from various sources such as Excel files, databases, APIs, and third-party services is a common requirement in data processing and analysis. Below is a guide on how to extract data from these different sources using Python.\n",
    "\n",
    "1. Extracting Data from Excel Files\n",
    "You can use the pandas library to read Excel files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0d730e9-1167-492c-ad18-c2ddf4077085",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def extract_from_excel(file_path, sheet_name=0):\n",
    "    \"\"\"\n",
    "    Extracts data from an Excel file.\n",
    "    :param file_path: Path to the Excel file.\n",
    "    :param sheet_name: Name or index of the sheet to read.\n",
    "    :return: DataFrame containing the data.\n",
    "    \"\"\"\n",
    "    data = pd.read_excel(file_path, sheet_name=sheet_name)\n",
    "    print(f\"Data extracted from Excel: {file_path}\")\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e2227a-e8da-4ef0-aa20-479deaad21b6",
   "metadata": {},
   "source": [
    "2. Extracting Data from Databases\n",
    "For relational databases (like MySQL, PostgreSQL, SQLite), you can use the sqlite3 module or SQLAlchemy.\n",
    "\n",
    "Using SQLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7be8c44b-53a5-4b6e-bf50-24b3ac017c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "def extract_from_database(db_name, query):\n",
    "    \"\"\"\n",
    "    Extracts data from a SQLite database.\n",
    "    :param db_name: Name of the database file.\n",
    "    :param query: SQL query to execute.\n",
    "    :return: DataFrame containing the data.\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(db_name)\n",
    "    data = pd.read_sql_query(query, conn)\n",
    "    conn.close()\n",
    "    print(f\"Data extracted from database: {db_name}\")\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a827e6d-c8a0-4457-a65e-9be3b11f1965",
   "metadata": {},
   "source": [
    "3. Extracting Data from APIs\n",
    "You can use the requests library to interact with REST APIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "056155b1-8a2e-477e-a0a6-1b1181a76d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def extract_from_api(url, params=None):\n",
    "    \"\"\"\n",
    "    Extracts data from a REST API.\n",
    "    :param url: URL of the API endpoint.\n",
    "    :param params: Dictionary of query parameters (optional).\n",
    "    :return: JSON response from the API.\n",
    "    \"\"\"\n",
    "    response = requests.get(url, params=params)\n",
    "    response.raise_for_status()  # Raise an error for bad responses\n",
    "    data = response.json()\n",
    "    print(f\"Data extracted from API: {url}\")\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5107930a-20b7-4db0-addd-2948e2d63b8f",
   "metadata": {},
   "source": [
    "4. Extracting Data from Third-Party Services\n",
    "Third-party services often provide their APIs to fetch data. The process is similar to extracting data from standard APIs. For example, fetching data from a service like Salesforce, Twitter, or any other platform would usually involve using their respective SDKs or REST APIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "857d3a76-6efb-40b6-aeda-01341badba8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example for a hypothetical third-party service\n",
    "def extract_from_third_party_service(api_endpoint, headers):\n",
    "    \"\"\"\n",
    "    Extracts data from a third-party service.\n",
    "    :param api_endpoint: Endpoint of the third-party API.\n",
    "    :param headers: Authorization or other necessary headers.\n",
    "    :return: JSON response from the third-party service.\n",
    "    \"\"\"\n",
    "    response = requests.get(api_endpoint, headers=headers)\n",
    "    response.raise_for_status()  # Raise an error for bad responses\n",
    "    data = response.json()\n",
    "    print(f\"Data extracted from third-party service: {api_endpoint}\")\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d385bc2-0203-45eb-99bc-2edd08e5fd0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "08a05cc0-5da0-4af5-ba60-07a3ea9d71f9",
   "metadata": {},
   "source": [
    "Complete ETL Example\n",
    "You can combine all these extraction methods into a complete ETL process. Hereâ€™s how you can structure the ETL pipeline:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84712f79-6659-4b81-9ed9-598e7b2ce468",
   "metadata": {},
   "source": [
    "Summary\n",
    "This code provides a flexible ETL pipeline that can gather data from various sources, including Excel files, databases, APIs, and third-party services. You can customize the function parameters to fit your specific needs and data structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb71742-e617-4002-984a-b9933e29c686",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c4382b2a-157d-4815-a22f-3aa46a85371d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data extracted from Excel: C:/Users/USER/Downloads/data.xlsx\n",
      "An error occurred: Execution failed on sql 'SELECT * FROM your_table;': no such table: your_table\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import requests\n",
    "import os\n",
    "\n",
    "def extract_from_excel(file_path, sheet_name=0):\n",
    "    \"\"\"Extracts data from an Excel file.\"\"\"\n",
    "    data = pd.read_excel(file_path, sheet_name=sheet_name)\n",
    "    print(f\"Data extracted from Excel: {file_path}\")\n",
    "    return data\n",
    "\n",
    "def extract_from_database(db_name, query):\n",
    "    \"\"\"Extracts data from a SQLite database.\"\"\"\n",
    "    conn = sqlite3.connect(db_name)\n",
    "    data = pd.read_sql_query(query, conn)\n",
    "    conn.close()\n",
    "    print(f\"Data extracted from database: {db_name}\")\n",
    "    return data\n",
    "\n",
    "def extract_from_api(api_url, params, headers=None):\n",
    "    \"\"\"Extracts data from a REST API.\"\"\"\n",
    "    response = requests.get(api_url, params=params, headers=headers)\n",
    "    response.raise_for_status()  # Raise an error for bad responses\n",
    "    data = pd.json_normalize(response.json())\n",
    "    print(f\"Data extracted from API: {api_url}\")\n",
    "    return data\n",
    "\n",
    "def extract_from_third_party(third_party_url, headers=None):\n",
    "    \"\"\"Extracts data from a third-party service.\"\"\"\n",
    "    response = requests.get(third_party_url, headers=headers)\n",
    "    response.raise_for_status()\n",
    "    data = pd.json_normalize(response.json())\n",
    "    print(f\"Data extracted from third-party service: {third_party_url}\")\n",
    "    return data\n",
    "\n",
    "def transform_data(data):\n",
    "    \"\"\"Transforms the extracted data (cleaning and formatting).\"\"\"\n",
    "    # Example transformation: removing leading/trailing whitespace\n",
    "    data_cleaned = data.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "    # Further transformation steps can be added here\n",
    "    print(\"Data transformation completed.\")\n",
    "    return data_cleaned\n",
    "\n",
    "def load_to_database(data, db_name, table_name):\n",
    "    \"\"\"Loads the cleaned data into a SQLite database.\"\"\"\n",
    "    conn = sqlite3.connect(db_name)\n",
    "    data.to_sql(table_name, conn, if_exists='replace', index=False)\n",
    "    conn.close()\n",
    "    print(f\"Data loaded into database: {db_name}, table: {table_name}\")\n",
    "\n",
    "def etl_pipeline(excel_file, db_name, query, api_url, params, third_party_url, headers):\n",
    "    \"\"\"Full ETL pipeline that gathers data from various sources.\"\"\"\n",
    "    \n",
    "    # Extract from Excel\n",
    "    excel_data = extract_from_excel(excel_file)\n",
    "    \n",
    "    # Extract from Database\n",
    "    db_data = extract_from_database(db_name, query)\n",
    "    \n",
    "    # Extract from API\n",
    "    api_data = extract_from_api(api_url, params, headers)\n",
    "    \n",
    "    # Extract from Third-party Service\n",
    "    third_party_data = extract_from_third_party(third_party_url, headers)\n",
    "    \n",
    "    # Combine all extracted data into one DataFrame\n",
    "    combined_data = pd.concat([excel_data, db_data, api_data, third_party_data], ignore_index=True)\n",
    "    \n",
    "    # Transform\n",
    "    cleaned_data = transform_data(combined_data)\n",
    "    \n",
    "    # Load the cleaned data to the database\n",
    "    load_to_database(cleaned_data, db_name, 'cleaned_data')\n",
    "    \n",
    "    return cleaned_data\n",
    "\n",
    "# Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Define paths and parameters\n",
    "    excel_file_path = 'C:/Users/USER/Downloads/data.xlsx'  # Ensure this file exists\n",
    "    db_name = 'datawarehouse.db'  # SQLite database name\n",
    "    sql_query = 'SELECT * FROM your_table;'  # Ensure this table exists in the database\n",
    "    api_url = 'https://api.example.com/data'  # Replace with actual API URL\n",
    "    params = {'param1': 'value1'}  # Adjust parameters as needed\n",
    "    third_party_url = 'https://thirdparty.example.com/data'  # Replace with actual URL\n",
    "    headers = {'Authorization': 'Bearer YOUR_TOKEN'}  # Optional headers\n",
    "    \n",
    "    # Check if the Excel file exists\n",
    "    if not os.path.exists(excel_file_path):\n",
    "        raise FileNotFoundError(f\"The Excel file at {excel_file_path} was not found.\")\n",
    "    \n",
    "    # Run the ETL pipeline\n",
    "    try:\n",
    "        final_data = etl_pipeline(excel_file_path, db_name, sql_query, api_url, params, third_party_url, headers)\n",
    "        print(final_data)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5555e22a-abc8-4afc-80d3-1af28493e0ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
